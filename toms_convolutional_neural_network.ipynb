{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"toms_convolutional_neural_network.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3DR-eO17geWu"},"source":["# Convolutional Neural Network"]},{"cell_type":"markdown","metadata":{"id":"EMefrVPCg-60"},"source":["### Importing the libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Run this if you're running on an ODH Jup Hub\n","# pip install keras"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GzWTHPwBoOaL","executionInfo":{"status":"ok","timestamp":1620203248810,"user_tz":-600,"elapsed":717,"user":{"displayName":"Tom Corcoran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghxi-8GO_G09dcz-opxYwlLugIAPotCerLa3aNxrw=s64","userId":"12314001865211030666"}},"outputId":"249911bd-5c4c-4c08-abae-9804c3f1689b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4OdIzUy9omFN","executionInfo":{"status":"ok","timestamp":1620203710294,"user_tz":-600,"elapsed":980,"user":{"displayName":"Tom Corcoran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghxi-8GO_G09dcz-opxYwlLugIAPotCerLa3aNxrw=s64","userId":"12314001865211030666"}},"outputId":"1806867c-1949-49de-e877-42ce588bc57d"},"source":["%cd /content/drive/MyDrive/mbo/21-q2/1-certification-DL-2-my-code/2-cnn-1\n","! ls"],"execution_count":19,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/mbo/21-q2/1-certification-DL-2-my-code/2-cnn-1\n","dataset  toms_convolutional_neural_network.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ad2OQAQFq7bm","executionInfo":{"status":"ok","timestamp":1620204150963,"user_tz":-600,"elapsed":103576,"user":{"displayName":"Tom Corcoran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghxi-8GO_G09dcz-opxYwlLugIAPotCerLa3aNxrw=s64","userId":"12314001865211030666"}},"outputId":"7dbd8ea5-9c5e-400f-e8e4-097d23abe45d"},"source":["! git clone https://github.com/tnscorcoran/Part-2-CNN"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Cloning into 'Part-2-CNN'...\n","remote: Enumerating objects: 10015, done.\u001b[K\n","remote: Total 10015 (delta 0), reused 0 (delta 0), pack-reused 10015\u001b[K\n","Receiving objects: 100% (10015/10015), 216.39 MiB | 11.88 MiB/s, done.\n","Resolving deltas: 100% (1/1), done.\n","Checking out files: 100% (10004/10004), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hmPRjUcDxGBe","executionInfo":{"status":"ok","timestamp":1620205429615,"user_tz":-600,"elapsed":856,"user":{"displayName":"Tom Corcoran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghxi-8GO_G09dcz-opxYwlLugIAPotCerLa3aNxrw=s64","userId":"12314001865211030666"}},"outputId":"887fec43-715a-4b88-e734-a4fe22a46ba8"},"source":["%cd /content/drive/MyDrive/mbo/21-q2/1-certification-DL-2-my-code/2-cnn-1\n","! pwd\n","! ls"],"execution_count":25,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/mbo/21-q2/1-certification-DL-2-my-code/2-cnn-1\n","/content/drive/MyDrive/mbo/21-q2/1-certification-DL-2-my-code/2-cnn-1\n","Part-2-CNN  toms_convolutional_neural_network.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sCV30xyVhFbE","executionInfo":{"status":"ok","timestamp":1620205439193,"user_tz":-600,"elapsed":711,"user":{"displayName":"Tom Corcoran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghxi-8GO_G09dcz-opxYwlLugIAPotCerLa3aNxrw=s64","userId":"12314001865211030666"}}},"source":["import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"FIleuCAjoFD8","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1620205442016,"user_tz":-600,"elapsed":936,"user":{"displayName":"Tom Corcoran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghxi-8GO_G09dcz-opxYwlLugIAPotCerLa3aNxrw=s64","userId":"12314001865211030666"}},"outputId":"6807556b-1905-4ccc-c248-d12e091feab4"},"source":["tf.__version__"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.4.1'"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"oxQxCBWyoGPE"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"MvE-heJNo3GG"},"source":["### Preprocessing the Training set"]},{"cell_type":"code","metadata":{"id":"0koUcJMJpEBD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620205504304,"user_tz":-600,"elapsed":1203,"user":{"displayName":"Tom Corcoran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghxi-8GO_G09dcz-opxYwlLugIAPotCerLa3aNxrw=s64","userId":"12314001865211030666"}},"outputId":"965ebc31-2e62-4d51-c854-340c7dd8cb7c"},"source":["train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/mbo/21-q2/1-certification-DL-2-my-code/2-cnn-1/Part-2-CNN/dataset/training_set',\n","                                                 target_size = (64, 64),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'binary')"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Found 8000 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mrCMmGw9pHys"},"source":["### Preprocessing the Test set"]},{"cell_type":"code","metadata":{"id":"SH4WzfOhpKc3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620205527915,"user_tz":-600,"elapsed":1455,"user":{"displayName":"Tom Corcoran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghxi-8GO_G09dcz-opxYwlLugIAPotCerLa3aNxrw=s64","userId":"12314001865211030666"}},"outputId":"484984ed-6a43-4a78-ea11-c01f0c4c2993"},"source":["test_datagen = ImageDataGenerator(rescale = 1./255)\n","test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/mbo/21-q2/1-certification-DL-2-my-code/2-cnn-1/Part-2-CNN/dataset/test_set',\n","                                            target_size = (64, 64),\n","                                            batch_size = 32,\n","                                            class_mode = 'binary')"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Found 2000 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"af8O4l90gk7B"},"source":["## Part 2 - Building the CNN"]},{"cell_type":"markdown","metadata":{"id":"ces1gXY2lmoX"},"source":["### Initialising the CNN"]},{"cell_type":"code","metadata":{"id":"SAUt4UMPlhLS"},"source":["cnn = tf.keras.models.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u5YJj_XMl5LF"},"source":["### Step 1 - Convolution"]},{"cell_type":"code","metadata":{"id":"XPzPrMckl-hV"},"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tf87FpvxmNOJ"},"source":["### Step 2 - Pooling"]},{"cell_type":"code","metadata":{"id":"ncpqPl69mOac"},"source":["cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaTOgD8rm4mU"},"source":["### Adding a second convolutional layer"]},{"cell_type":"code","metadata":{"id":"i_-FZjn_m8gk"},"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tmiEuvTunKfk"},"source":["### Step 3 - Flattening"]},{"cell_type":"code","metadata":{"id":"6AZeOGCvnNZn"},"source":["cnn.add(tf.keras.layers.Flatten())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dAoSECOm203v"},"source":["### Step 4 - Full Connection"]},{"cell_type":"code","metadata":{"id":"8GtmUlLd26Nq"},"source":["cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTldFvbX28Na"},"source":["### Step 5 - Output Layer"]},{"cell_type":"code","metadata":{"id":"1p_Zj1Mc3Ko_"},"source":["cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D6XkI90snSDl"},"source":["## Part 3 - Training the CNN"]},{"cell_type":"markdown","metadata":{"id":"vfrFQACEnc6i"},"source":["### Compiling the CNN"]},{"cell_type":"code","metadata":{"id":"NALksrNQpUlJ"},"source":["cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ehS-v3MIpX2h"},"source":["### Training the CNN on the Training set and evaluating it on the Test set"]},{"cell_type":"code","metadata":{"id":"XUj1W4PJptta"},"source":["cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3PZasO0006Z"},"source":["## Part 4 - Making a single prediction"]},{"cell_type":"code","metadata":{"id":"gsSiWEJY1BPB"},"source":["import numpy as np\n","from keras.preprocessing import image\n","test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = cnn.predict(test_image)\n","training_set.class_indices\n","if result[0][0] == 1:\n","  prediction = 'dog'\n","else:\n","  prediction = 'cat'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ED9KB3I54c1i"},"source":["print(prediction)"],"execution_count":null,"outputs":[]}]}